{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afda9d34-7492-403f-bff6-5fd0376ef2cc",
   "metadata": {},
   "source": [
    "# hls4ml and oneAPI\n",
    "\n",
    "This tutorial is based on the hls4ml tutorial notebooks (https://github.com/fastmachinelearning/hls4ml-tutorial/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87730f69-a704-44b8-a2be-61f6b4b24dae",
   "metadata": {},
   "source": [
    "## Load the hls4ml jet tagging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9126a00e-d49d-4cd5-b8c5-6218477332dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 14:27:15.452891: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-17 14:27:15.490803: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-17 14:27:15.490848: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-17 14:27:15.490871: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 14:27:15.497821: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-17 14:27:15.498372: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-17 14:27:16.652905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "import ndjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be13b282-cce5-48da-8d83-9176e48b4881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = fetch_openml('hls4ml_lhc_jets_hlf', as_frame=False, parser='liac-arff')\n",
    "X, y = data['data'], data['target']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y, 5)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(y[:5])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "np.save('X_train_val.npy', X_train_val)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train_val.npy', y_train_val)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('classes.npy', le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6da688-c6fd-4da9-a85e-61df121a8cc9",
   "metadata": {},
   "source": [
    "## Create a small model for jet tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77687719-c67a-41bb-be9d-78c56f3da861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693cfecb-f01c-4eca-a584-f1dbf40784cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e5c2333-f7ce-42b8-971d-d7425fa76677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc1 (Dense)                 (None, 32)                544       \n",
      "                                                                 \n",
      " relu1 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 32)                1056      \n",
      "                                                                 \n",
      " relu2 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 32)                1056      \n",
      "                                                                 \n",
      " relu3 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 5)                 165       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2821 (11.02 KB)\n",
      "Trainable params: 2821 (11.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu1'))\n",
    "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu2'))\n",
    "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu3'))\n",
    "model.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "47e05f23-585c-4a07-8ce3-a69615eeed70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 1.1002 - accuracy: 0.6138 - val_loss: 0.9022 - val_accuracy: 0.7147\n",
      "Epoch 2/10\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.8604 - accuracy: 0.7222 - val_loss: 0.8420 - val_accuracy: 0.7265\n",
      "Epoch 3/10\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.8266 - accuracy: 0.7293 - val_loss: 0.8212 - val_accuracy: 0.7304\n",
      "Epoch 4/10\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.8092 - accuracy: 0.7330 - val_loss: 0.8064 - val_accuracy: 0.7336\n",
      "Epoch 5/10\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.7965 - accuracy: 0.7359 - val_loss: 0.7958 - val_accuracy: 0.7370\n",
      "Epoch 6/10\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.7869 - accuracy: 0.7385 - val_loss: 0.7866 - val_accuracy: 0.7391\n",
      "Epoch 7/10\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.7791 - accuracy: 0.7406 - val_loss: 0.7798 - val_accuracy: 0.7408\n",
      "Epoch 8/10\n",
      "3891/3891 [==============================] - 10s 3ms/step - loss: 0.7725 - accuracy: 0.7425 - val_loss: 0.7741 - val_accuracy: 0.7426\n",
      "Epoch 9/10\n",
      "3891/3891 [==============================] - 9s 2ms/step - loss: 0.7667 - accuracy: 0.7443 - val_loss: 0.7688 - val_accuracy: 0.7444\n",
      "Epoch 10/10\n",
      "3891/3891 [==============================] - 8s 2ms/step - loss: 0.7613 - accuracy: 0.7456 - val_loss: 0.7645 - val_accuracy: 0.7458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x75d2e8acec50>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_split=0.25,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "68558a87-befd-4cad-90a1-37ee6dd1bb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5188/5188 [==============================] - 9s 2ms/step\n",
      "Achieved test accuracy of 74.93\n"
     ]
    }
   ],
   "source": [
    "y_keras = model.predict(X_test)\n",
    "keras_accuracy = np.sum(np.argmax(y_test, axis=1) == np.argmax(y_keras, axis=1))/y_test.shape[0]\n",
    "\n",
    "print(f\"Achieved test accuracy of {(100 * keras_accuracy):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ee69d-15df-4fbd-a943-485bb2a05258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9fb89aa-7a7c-4717-8537-2cfdf97a860f",
   "metadata": {},
   "source": [
    "# Convert the model\n",
    "\n",
    "Creates a directory with oneAPI code for your model and its weights\n",
    "\n",
    "## Datatypes in HLS\n",
    "\n",
    "Fixed point representation is used instead of floating point\n",
    "\n",
    "For example the hls4ml default `fixed<16,6>` corresponds to:\n",
    "\n",
    "```\n",
    "+-------------------------+---------------------------+\n",
    "|  Integer part (6 bits)  | Fractional part (10 bits) |\n",
    "+-------------------------+---------------------------+\n",
    "| 101010                  |                1010101010 |\n",
    "+-------------------------+---------------------------+\n",
    "|           Full bitwidth (16 bits)                   |\n",
    "+-------------------------+---------------------------+\n",
    "```\n",
    "\n",
    "Read more:\n",
    "\n",
    "https://github.com/hlslibs/ac_types/blob/v3.7/pdfdocs/ac_datatypes_ref.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54cb6557-1736-4761-83ab-d58eb81fac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "-----------------------------------\n",
      "Configuration\n",
      "{'Model': {'Precision': {'default': 'fixed<16,6>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'BramFactor': 1000000000, 'TraceOutput': False}}\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model', backend='oneAPI')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "print(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, backend='oneAPI', output_dir='model_1/hls4ml_prj', part='Agilex7'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a843f2b3-e11a-43fa-8687-55740982510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "/opt/intel/oneapi/2025.0/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/lauri/local/icl/notebooks/model_1/hls4ml_prj/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/myproject_bridge.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libmyproject-89e53233.so\u001b[0m\n",
      "[100%] Built target lib\n",
      "Achieved test accuracy of 74.92%\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)\n",
    "\n",
    "hls_accuracy = np.sum(np.argmax(y_test, axis=1) == np.argmax(y_hls, axis=1))/y_test.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88c1680b-73b5-430b-b463-ee2819ec583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved test accuracy of 74.92%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Achieved test accuracy of {(100 * hls_accuracy):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01533ec6-2f11-4f33-90a5-2cdc2989fa01",
   "metadata": {},
   "source": [
    "## Create a report of the FPGA resource usage\n",
    "\n",
    "The report is available in the project directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee7312fb-44ef-43df-842d-fa2ec6bcffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/2025.0/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/lauri/local/icl/notebooks/model_1/hls4ml_prj/build\n",
      "[ 25%] \u001b[34m\u001b[1mTo compile manually:\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -I../src -I../src/firmware -fsycl -fintelfpga -Wall -qactypes -Wno-unused-label -fconstexpr-steps=134217728 -DFPGA_HARDWARE -c ../src/firmware/myproject.cpp -o CMakeFiles/report.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -I../src -I../src/firmware -fsycl -fintelfpga -Wall -qactypes -Wno-unused-label -fconstexpr-steps=134217728 -DFPGA_HARDWARE -c ../src/myproject_test.cpp -o CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "\u001b[34m\u001b[1m\u001b[0m\n",
      "\u001b[34m\u001b[1mTo link manually:\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -fsycl -fintelfpga -Wno-unused-label -fconstexpr-steps=134217728 -Xshardware -Xstarget=Agilex7 -Wno-unused-label -fsycl-link=early -o myproject.report CMakeFiles/report.dir/src/firmware/myproject.cpp.o CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "[ 25%] Built target displayReportCompileCommands\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/report.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable myproject.report\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "icpx: warning: appending to an existing archive 'myproject.report' [-Warchive-append]\n",
      "Segmentation fault (core dumped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Built target report\n",
      "['ALUTs ', 'FFs  ', 'RAMs ', 'DSPs ', 'MLABs', 'Frac. DSPs']\n",
      "['974400', '1948800', '7110', '4510', '24360', '0']\n",
      "{'name': 'Total', 'parent': 'estimatedResources', 'classes': ['summary-highlight', 'nohover'], 'data': [126605, 139081, 8, 16, 18, 5], 'data_percent': [12.993124, 7.1367507, 0.11251758, 0.354767174]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hls_model.build(build_type='report')\n",
    "with open(\"model_1/hls4ml_prj/build/myproject.report.prj/reports/resources/json/summary.ndjson\", \"r\") as f:\n",
    "    summary = ndjson.load(f)\n",
    "\n",
    "resource_names = list(filter(lambda x: x[\"name\"] == \"Estimated Resource Usage\", summary))[0]['columns'][1:]\n",
    "available = list(filter(lambda x: x[\"name\"] == \"Available\", summary))[0]['data']\n",
    "estimated_resources = list(filter(lambda x: x[\"name\"] == \"Total\", summary))[0]['data']\n",
    "\n",
    "print(resource_names)\n",
    "print(available)\n",
    "print(estimated_resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713aeb7-7bc6-4628-9adb-901dbf235a41",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "See how changing the bitwidth affects the accuracy as well as resource usage.\n",
    "\n",
    "Loop over several bitwidths and plot the accuracy and resource usage as a function of bitwidth.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8e2c1a-49e4-408e-b3ad-ed56d27767c9",
   "metadata": {},
   "source": [
    "# Quantization Aware Training\n",
    "\n",
    "You can achieve similar performance with significantly lower bitwidths by quantizing during training.\n",
    "\n",
    "This can be achieved with QKeras, which emulates fixed bitwidths during forward pass.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d07e096-143c-49e7-ad1b-c96f7d478c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qkeras\n",
    "from qkeras import QDense\n",
    "from qkeras.quantizers import quantized_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "44665eb8-3e32-4ba7-813e-d055938cf6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x75d30c6b3f70>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGdCAYAAAAvwBgXAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR9NJREFUeJzt3XucTPXjx/HXmdm73Z21WpZ23QkhRWp1I0q6IVTfbghFFEmhb5G+aVW6UuhGv75KkVvKFymUkBTlmvttF+u2u3aZ2Z05vz8m+/1uxC47e2Zm38/HYx6PPmfO7HlPLvN2Pmc+xzBN00RERETEAjarA4iIiEjZpSIiIiIillEREREREcuoiIiIiIhlVERERETEMioiIiIiYhkVEREREbGMioiIiIhYJsTqAGfi8XhIS0sjJiYGwzCsjiMiIiJFYJom2dnZVKlSBZvtzOc8/LqIpKWlkZycbHUMEREROQe7d+8mKSnpjPv4dRGJiYkBvG8kNjbW4jQiIiJSFFlZWSQnJxd8jp+JXxeRk9MxsbGxKiIiIiIBpiiXVehiVREREbGMioiIiIhYRkVERERELOPX14gUhWma5Ofn43a7rY4iJSw0NBS73W51DBER8aGALiIul4v09HRyc3OtjiI+YBgGSUlJREdHWx1FRER8JGCLiMfjYfv27djtdqpUqUJYWJgWPQsipmmSkZHBnj17qFOnjs6MiIgEqYAtIi6XC4/HQ3JyMlFRUVbHER9ISEhgx44d5OXlqYiIiASpgL9Y9WxLx0rg0hkuEZHgp09xERERsUypFZFRo0ZhGAYDBgworUOKiIiInyuVIrJy5UomTJhA48aNS+NwUgIWLVqEYRgcPXrUZ8d47rnnaNKkic9+voiI+D+fF5Fjx45x77338t5771G+fHlfHy5g7N69mwcffLDgGz/VqlWjf//+HDp0qNSztGzZ8pQzVS1atCA9PR2Hw1HqeUREpOzweRHp27cvt9xyC23atDnrvk6nk6ysrEKPYLRt2zaaNWvG5s2b+fTTT9myZQvjx49n4cKFpKSkcPjwYasjEhYWRmJioi4YFREJVrmHYcq9sG2RpTF8WkSmTJnCL7/8QmpqapH2T01NxeFwFDySk5OLdTzTNMl15VvyME2zyDn79u1LWFgY8+fP57rrrqNq1aq0a9eOb775hr179/LPf/4T8H5rZObMmYVeGxcXx6RJkwrGgwcPpm7dukRFRVGzZk2effZZ8vLyCp4/Of3x8ccfU716dRwOB3fffTfZ2dkAdOvWjcWLF/Pmm29iGAaGYbBjx45TpmZatmxZ8Pz/Pnbs2AHA0aNH6dmzJwkJCcTGxnL99dezZs2aQtlHjRpFpUqViImJoUePHpw4caLI/89ERKQE7f4JJlwLG+fArEfBnXf21/iIz9YR2b17N/3792fBggVEREQU6TVDhw5l4MCBBeOsrKxilZHjeW4aDJtX7KwlYf3zbYkKO/v/zsOHDzNv3jxGjhxJZGRkoecSExO59957+eyzz3jnnXeKdNyYmBgmTZpElSpV+P333+nVqxcxMTE89dRTBfts3bqVmTNnMmfOHI4cOcKdd97JqFGjGDlyJG+++SZ//PEHDRs25Pnnnwf+u37H/5o+fToul6tg3LdvX9atW0elSpUA6NKlC5GRkcydOxeHw8GECRNo3bo1f/zxB/Hx8Xz++ec899xzvP3221x99dV8/PHHvPXWW9SsWbNI71NEREqAxwPLxsDC58GTD/E1ocsksIdaFslnRWTVqlUcOHCAyy67rGCb2+1myZIljB07FqfTecoiVeHh4YSHh/sqkl/YvHkzpmlSv3790z5fv359jhw5QkZGRpF+3jPPPFPw39WrV2fQoEFMmTKlUBHxeDxMmjSJmJgYAO6//34WLlzIyJEjcTgchIWFERUVRWJi4t8eJz4+vuC/X3/9db799ltWrFhBZGQkP/zwAz/99BMHDhwo+PUbPXo0M2fOZNq0aTz00EO88cYb9OjRgx49egDwwgsv8M033+isiIhIack5BDN7w+b53nHDTnDrGxARa2ksnxWR1q1b8/vvvxfa1r17d+rVq8fgwYN9slJmZKid9c+3LfGfW9RjF8fZpnLCwsKK9HM+++wz3nrrLbZu3cqxY8fIz88nNrbwb6rq1asXlBCAypUrc+DAgWLlPWnu3LkMGTKEL7/8krp16wKwZs0ajh07RoUKFQrte/z4cbZu3QrAhg0b6N27d6HnU1JS+O67784ph4iIFMPOH2FaD8hOg5AIaPcSXNYV/OA6QJ8VkZiYGBo2bFhoW7ly5ahQocIp20uKYRhFmh6xUu3atTEMgw0bNtCxY8dTnt+wYQMJCQnExcVhGMYpheV/r/9YtmwZ9957LyNGjKBt27Y4HA6mTJnCq6++Wug1oaGFT7kZhoHH4yl29vXr13P33XczatQobrzxxoLtx44do3LlyixatOiU18TFxRX7OCIiUkI8HvjhVfjuRTA9UKGOdyom0Tefw+fCvz+1g1CFChW44YYbeOedd3j88ccLXSeyb98+Jk+eTN++fQHvtRrp6ekFz2/evLnQnYZ//PFHqlWrVnBxK8DOnTuLnSksLAy3233GfQ4ePMhtt91Gp06dePzxxws9d9lll7Fv3z5CQkKoXr36aV9fv359VqxYwQMPPFCwbfny5cXOKiIiRXTsAEx/CLb9eea58d1wy6sQ7l93NC/VInK6fzGXRWPHjqVFixa0bduWF154gRo1arBu3TqefPJJ6taty7BhwwC4/vrrGTt2LCkpKbjdbgYPHlzo7EadOnXYtWsXU6ZM4fLLL+err75ixowZxc5TvXp1VqxYwY4dO4iOji50PchJnTp1Iioqiueee459+/YVbE9ISKBNmzakpKTQoUMHXn75ZerWrUtaWhpfffUVHTt2pFmzZvTv359u3brRrFkzrrrqKiZPnsy6det0saqIiC9sXwJf9IRj+yEkEm4ZDU3u9YupmL/SvWYsUKdOHVauXEnNmjW58847qVatGu3ataNu3bosXbqU6GhvW3311VdJTk7mmmuu4Z577mHQoEGF7jR8++238/jjj9OvXz+aNGnCjz/+yLPPPlvsPIMGDcJut9OgQQMSEhLYtWvXKfssWbKEtWvXUq1aNSpXrlzw2L17N4Zh8PXXX3PttdfSvXt36taty913383OnTsLvlVz11138eyzz/LUU0/RtGlTdu7cSZ8+fc7x/6CIiJyWxw2LRsH/tfeWkIR68NAiuPQ+vywhAIZZnAUwSllWVhYOh4PMzMxTLsA8ceIE27dvp0aNGkX+erA/Gz58OK+99hoLFizgyiuvtDqOXwi2X2MREZ/K3uc9C7Lje+/40vug3SsQFnXm1/nAmT6//0rXiPiJESNGUL16dZYvX07z5s2x2XSySkREimjrt97rQXIyILQc3Po6XHKX1amKREXEj3Tv3t3qCCIiEkjc+bAoFb5/FTChUkPoPBES6lqdrMhURERERAJR5l7vVMyuH73jpt3hplQIjTzz6/yMioiIiEig2bzAOxVz/DCExcDtb3pXSg1AKiIiIiKBwp0H3/4Llr7pHVe+xDsVU6GWtbnOg4qIiIhIIDi6G6Y9CHt+8o6bPwQ3vgAhgX2PNhURERERf7fxa5jZB04chXAHtB8DDdpbnapEqIiIiIj4q3wXfPMcLH/bO65yGXSZCOWrW5mqRGmxCj/TsmVLBgwY4PPjLFq0CMMwOHr0qM+PJSIi5+DIDviw7X9LyJV94cF5QVVCQEXEEt26dcMwjFMeW7Zs8cnxTlduWrRoQXp6Og6HwyfHFBGR87B+Noy/FtJ+gYg4uPtTuOlFCAmzOlmJ09SMRW666SYmTpxYaFtCQkKpHT8sLIzExMRSO56IiBRBvhPmPwM/vesdJzWHzh9AXFVrc/mQzohYJDw8nMTExEIPu91+yn5HjhzhgQceoHz58kRFRdGuXTs2b95c8PyhQ4f4xz/+wYUXXkhUVBSNGjXi008/LXi+W7duLF68mDfffLPgzMuOHTtOmZqZNGkScXFxzJs3j/r16xMdHc1NN91Eenp6wc/Kz8/nscceIy4ujgoVKjB48GC6du1Khw4dfPb/SUSkzDi0FT644b8l5Kr+0P3roC4hEGxFxDTBlWPNw0f3DuzWrRs///wzs2fPZtmyZZimyc0330xeXh7gvTFc06ZN+eqrr1i7di0PPfQQ999/Pz/95P1615tvvklKSgq9evUiPT2d9PR0kpOTT3us3NxcRo8ezccff8ySJUvYtWsXgwYNKnj+pZdeYvLkyUycOJGlS5eSlZXFzJkzffK+RUTKlLVfwITrIH0NRMbDPVPhhufBHmp1Mp8LrqmZvFx4sYo1x346DcLKFXn3OXPmEB0dXTBu164dU6dOLbTP5s2bmT17NkuXLqVFixYATJ48meTkZGbOnEmXLl248MILC5WFRx99lHnz5vH555/TvHlzHA4HYWFhREVFnXUqJi8vj/Hjx1OrlndhnH79+vH8888XPD9mzBiGDh1Kx44dARg7dixff/11kd+ziIj8Rd5x+M9QWPXnVH3VFtDpfXBcaG2uUhRcRSSAtGrVinHjxhWMy5U7tcRs2LCBkJAQrrjiioJtFSpU4KKLLmLDhg0AuN1uXnzxRT7//HP27t2Ly+XC6XQSFVX82z5HRUUVlBCAypUrc+DAAQAyMzPZv38/zZs3L3jebrfTtGlTPB5PsY8lIlLmHdwMU7vB/rWAAdc8AS2Hgr1sfTQH17sNjfKembDq2MVQrlw5ateufd6HfeWVV3jzzTd54403aNSoEeXKlWPAgAG4XK5i/6zQ0MKnAA3DwPTRlJOISJm25jOY8zjk5UC5BLjjXah1vdWpLBFcRcQwijU94u/q169Pfn4+K1asKJiaOXToEJs2baJBgwYALF26lPbt23PfffcB4PF4+OOPPwqeB+83ZNxu93llcTgcVKpUiZUrV3LttdcC3rMxv/zyC02aNDmvny0iUma4cmHuk/Drv73j6td4p2Jiyu63GIPrYtUgU6dOHdq3b0+vXr344YcfWLNmDffddx8XXngh7du3L9hnwYIF/Pjjj2zYsIGHH36Y/fv3F/o51atXZ8WKFezYsYODBw+e81TKo48+SmpqKrNmzWLTpk3079+fI0eOYBjGeb9XEZGgd2AjvNfqzxJieKdhHphVpksIqIj4vYkTJ9K0aVNuvfVWUlJSME2Tr7/+umAa5ZlnnuGyyy6jbdu2tGzZksTExFO+Tjto0CDsdjsNGjQgISGBXbt2nVOWwYMH849//IMHHniAlJQUoqOjadu2LREREef7NkVEgpdpesvHuy0hYyNEV4Kus6HlELCdumxDWWOYfnwRQFZWFg6Hg8zMTGJjYws9d+LECbZv306NGjX0QWgRj8dD/fr1ufPOO/nXv/5V4j9fv8YiEvCcx+CrJ+C3Kd5xzVbe60GiK1qby8fO9Pn9V8F1jYj41M6dO5k/fz7XXXcdTqeTsWPHsn37du655x6ro4mI+J99a2Fadzj4Bxg2aPVPuHog2DQZ8b9URKTIbDYbkyZNYtCgQZimScOGDfnmm2+oX7++1dFERPyHacKqSfCfIZB/AmKqeJdpr9bC6mR+SUVEiiw5OZmlS5daHUNExH+dyII5A7wrpQLUvgE6ToByFSyN5c9UREREREpC+hrvAmWHt4FhhzbDIeVRTcWchYqIiIjI+TBNWPk+zHsa3C5wJEPnDyG5+dlfK4FfRPz4Sz9ynvRrKyJ+7/hR+PIxWD/LO77oZmj/NkTFWxorkARsETm5jkZubi6RkZEWpxFfOLlMvd2u79mLiB/auwqmdoejO8EW6r1b7pV9vKt8S5EFbBGx2+3ExcUV3JQtKipKK3wGEY/HQ0ZGBlFRUYSEBOxvUxEJRqYJy8fBgmHgyYO4qtBlElzY1OpkASmg/4Y/eVv7k2VEgovNZqNq1aoqmCLiP3IPw6x+sOkr77j+bXD7WIiMszRWIPNpERk3bhzjxo1jx44dAFx88cUMGzaMdu3alcjPNwyDypUrU7FiRfLy8krkZ4r/CAsLw6arzUXEX+xe6V2gLHM32MOg7YtweU9NxZwnnxaRpKQkRo0aRZ06dTBNk48++oj27dvz66+/cvHFF5fYcex2u64jEBER3/B4YNkYWPg8ePKhfA3vVEyVJlYnCwqlfq+Z+Ph4XnnlFXr06HHWfYuzVr2IiEiJyzkEM/vA5nne8cV3wG1vQoQ+k87EL+8143a7mTp1Kjk5OaSkpJx2H6fTidPpLBhnZWWVVjwREZHCdi6DaQ9CdhrYw6HdS9C0m6ZiSpjPi8jvv/9OSkoKJ06cIDo6mhkzZtCgQYPT7puamsqIESN8HUlEROTveTyw9HX4diSYbqhQxzsVk9jQ6mRByedTMy6Xi127dpGZmcm0adN4//33Wbx48WnLyOnOiCQnJ2tqRkRESsexDJjxEGz91jtufBfc8hqER1ubK8AUZ2qm1K8RadOmDbVq1WLChAln3VfXiIiISKnZ/j180ROO7YOQSLhlNDS5V1Mx58AvrxE5yePxFDrrISIiYimPG5a8AotfAtMDCfW8UzEV61udrEzwaREZOnQo7dq1o2rVqmRnZ/PJJ5+waNEi5s2b58vDioiIFE32fpjeE7Yv8Y6b3Ac3vwxh5azNVYb4tIgcOHCABx54gPT0dBwOB40bN2bevHnccMMNvjysiIjI2W39Dqb3gpwMCC0Ht74Gl9xtdaoyx6dF5IMPPvDljxcRESk+dz4sSoXvXwVMqHixdyomoa7VycqkgL7XjIiISLFkpXkvSN251Dtu2h1uSoVQ3cXdKioiIiJSNmz+xvvV3NxDEBYDt70BjTpbnarMUxEREZHg5s6Db1+ApW94x4mNvVMxFWpZmUr+pCIiIiLB6+hu+KIH7F7hHV/eC258AUIjrM0lBVREREQkOG2aCzN6w4mjEO6A9mOgQXurU8lfqIiIiEhwyXfBwhGwbKx3XOUy6PwhxNewNpecloqIiIgEjyM7vHfM3bvKO77yEWgzAkLCLI0lf09FREREgsP62TCrHzgzIcIBHcZBvVusTiVnoSIiIiKBLd8J85+Bn971jpMu907FxFW1NpcUiYqIiIgErkNbYVp3SF/jHbd4DFoPA3uotbmkyFREREQkMK2dDrMfA1c2RMZDx/FQt63VqaSYVERERCSw5B2HeU/Dzx96x1VToNMH4LjQ2lxyTlREREQkcBzcDFO7wf61gAHXDISWT4NdH2eBSr9yIiISGH77HL4cAHk5EHUB3PEu1G5tdSo5TyoiIiLi31y5MPcp+PVj77j6NdDpfYhJtDaXlAgVERER8V8HNnqnYjI2AAZcNxiuewpsdquTSQlREREREf/062T4ehDk5UJ0JbjjPah5ndWppISpiIiIiH9xHvMWkDWfesc1W3pLSHRFS2OJb6iIiIiI/9i/zjsVc/APMGzQ6mm4+gmw2axOJj6iIiIiItYzTfjlI5g7GPJPQExl79og1a+yOpn4mIqIiIhYy5nt/Vru2mnece0bvKuklrvA0lhSOlRERETEOulrvFMxh7eBYffeJ6bFY5qKKUNUREREpPSZJqx8H+b9E9xOiE3y3jG36hVWJ5NSpiIiIiKl60QmzH4U1s/yjuu2gw7vQFS8tbnEEioiIiJSevb+4p2KOboTbKFwwwi48hEwDKuTiUVURERExPdME1aMh/nPgicP4qpC50mQ1NTqZGIxFREREfGt40dgVj/YOMc7rn8b3D4WIuMsjSX+QUVERER8Z/dKmPYgZO4CexjcOBKa99JUjBRQERERkZLn8cCysbBwBHjyoXwN6DIRqlxqdTLxMyoiIiJSsnIPw4zesHmed3zxHXDbmxARa20u8UsqIiIiUnJ2LoMvekDWXrCHQ7tR0LS7pmLkb/l06brU1FQuv/xyYmJiqFixIh06dGDTpk2+PKSIiFjB44HvX4VJt3hLSIXa0GshNHtQJUTOyKdFZPHixfTt25fly5ezYMEC8vLyuPHGG8nJyfHlYUVEpDQdy4DJnWHh82C6ofFd8NBiSGxkdTIJAIZpmmZpHSwjI4OKFSuyePFirr322rPun5WVhcPhIDMzk9hYzS2KiPidHT/AtB5wbB+ERMLNr8Cl9+ksSBlXnM/vUr1GJDMzE4D4+NMv4+t0OnE6nQXjrKysUsklIiLF5HHDktGweBSYHrjgIrjzI6hY3+pkEmBK7faGHo+HAQMGcNVVV9GwYcPT7pOamorD4Sh4JCcnl1Y8EREpquz98HEHWPSit4Q0uQ8e+k4lRM5JqU3N9OnTh7lz5/LDDz+QlJR02n1Od0YkOTlZUzMiIv5i63cw/SHIOQChUXDr63DJ3VanEj/jd1Mz/fr1Y86cOSxZsuRvSwhAeHg44eHhpRFJRESKw53vnYZZMhowoeLF0GUSJNS1OpkEOJ8WEdM0efTRR5kxYwaLFi2iRo0avjyciIj4QlYafNETdi71ji/rCu1egtBIa3NJUPBpEenbty+ffPIJs2bNIiYmhn379gHgcDiIjNRvYBERv7f5G5jxEOQegrBo7wqpjTpbnUqCiE+vETH+5utbEydOpFu3bmd9vb6+KyJiEXcefDcSfnjdO05sBF0+ggq1rM0lAcFvrhEpxSVKRESkpGTu8d4xd/cK7/jyXnDjCxAaYW0uCUq614yIiPzXpv/AzN5w/AiEx8LtY+DiDlankiCmIiIiIpDvgoUjYNlY77jKpdB5IsTrSwbiWyoiIiJlgGmaZJ3IP+1zRuYuomb1JCT9FwCczR7mxHXDICQcjueVZkyxQIjNoFy4dXVARUREpAzoOnElS/7IOGV7W9tKXg6dQIiRS6YZxaC83iz4oRn8sNiClGKFa+sm8H8PNrfs+CoiIiJBzjRNvt9cuISEkcfQkE/oHjIPgF88tXnU9Sh7SbAiopRhKiIiIkHOme/h5JcYVw+7gXI5u7FPfxBb+moA3Cn9aNRqGIvsodaFFMtYfZ9kFRERkSCX63IX/HfMtq+wf/kYOLMgMh46jsdety12C/NJ2aYiIiIS5HJd+YTjYnjYZOzTFng3Vk2BTh+A40Jrw0mZpyIiIhLk8g9sZkbYcBrYdno3XD0QWv0T7PoIEOvpd6GISDD7bSrJX/bHbsvhCLGUv28i1G5jdSqRAjarA4iIiA+4cmH2ozC9J/a8HJa5G9A7+k2VEPE7OiMiIhJsMjbB1G5wYD1gsO3iR7h3VQoNI8pbnUzkFCoiIiLBZPUn8NUTkJcL5SpCp/dZl10Hz6pfiQzVd2PE/6iIiIgEkMV/ZLBo04FTtoe6j3PzrtE0OTwXgK0xlzOjxnBy1sWz5cBuAKLCVETE/6iIiIgEkP5TfuVobuH7v1xk7OLt0LeobUvDbRq8nt+ZdzLa48nIArIK9rsgOryU04qcnYqIiEiAcHvMghLS4+oaRIQYNDowm9bbXyXUdJIdmsCcOs9jOi6jz19eG2a307lZUumHFjkLFRERkQBxPO+/K6Q+2bIKEfMGwbap3g212xDTcQL/KHeBRelEzo2KiIhIgMh15QPQwLaD8A+fhcNbwbBD62ehRX+waUUGCTwqIiIiAeK4M5/77At4NuTfGIfzIDYJOn8IVa+wOprIOVMREREJBCcyKf/1I7wQOsc7rtsOOrwDUfHW5hI5TzqPJyLi7/b+AhOuJXbbHPJMO2NDu8M/PlUJkaCgMyIiIv7KNGHFBJj/DHjyOFHuQu4+/DDH4y6ln2FYnU6kROiMiIiIPzp+BD67D/4zGDx5UO9Wfmwzg9VmbSK1MJkEEZ0RERGxwIk8N858z2mfs6etImpWT2xZuzHtYZxoNQLXZT05sHYfoBVSJbioiIiIlLLf9hzlrgnLC60L4mXS0/41g0OmYDPc7PRUpK/zMdbOqQZzFhTspSIiwURFRESklK3aeeSUEhJHNqNDx9PG/isAc9xXMjSvJ9lEFdovxGbQql7FUssq4msqIiIipSzX5S0hnS5LYlSnRhi7l2OfPggjKw3THo6n7Yu0vaw7bU9zQaoBhNh1eZ8EDxUREZFSdvzPIhITZhD64xvw7QtguqFCbYwuk7AnNkKTL1JWqIiIiJSyXJebeLK4f/tTsHqZd2OjO+HW1yA8xtpwIqVMRUREpJQlHlnJ1+HDScw8AiGRcPPLcOn9oLVBpAxSERERKS0eN3z/Kj23pWIzPByJqkH5rp9ApQZWJxOxjE+veFqyZAm33XYbVapUwTAMZs6c6cvDiYj4r+z98HFH+G4kNjxMzb+W+VdNUQmRMs+nRSQnJ4dLLrmEt99+25eHERHxb9sWwfirYftiCI1iXPlBPJnfm/AoXQ8i4tOpmXbt2tGuXTtfHkJExH953LBoFCx5BTChYgPoMon5Uw8CR7VUuwh+do2I0+nE6XQWjLOysixMIyJyZsddbj74YRuHclynPBftyqDT9ueofsy7QNmqC27nPxc+Tv7yfHYeygW0QqoI+FkRSU1NZcSIEVbHEBEpkrlr0xk9/49Ttl9rW8Proe9QwcjmmBnB03k9mL3nKtiTXmi/C6LDSyuqiN/yqyIydOhQBg4cWDDOysoiOTnZwkQiIn/v8J9nQi6qFEObBhUxzHyu3jWBK9P+D4D9UXX5su5IkiOr0vcvr61WoRz1EnWNiIhfFZHw8HDCw/UvBBEJDCeXar+sWhxPXhkN03pA2nLvk5f3pNKNI+kZGmFhQhH/51dFREQkkJwsIo1zV8D4kXD8CITHwu1vwcUdLU4nEhh8WkSOHTvGli1bCsbbt29n9erVxMfHU7VqVV8eWkTE55zOEzwdMpl/bPnKu6FyE+gyEeJrWppLJJD4tIj8/PPPtGrVqmB88vqPrl27MmnSJF8eWkTEt47spNumPlQLWe8dX9EHbhgBIZpeFikOnxaRli1bYpqmLw8hIlL6NsyBWY9Q7UQmmWYUPzd5gdbtelidSiQg+XRlVRGRoJLvhLmD4bN74UQmW8PqcYsrlYNJN1idTCRg6WJVEZGiOLwNpnaH9NXecUo/hu1oy56sbCLD9FepyLnSnx4REcCZ7+ZEnue0z4VsnEXU3AEYrmw8EeU5fstY8mu3JfMP71d1o0K1QqrIuVIREZEyb11aJl3GLyv4Ou5J4bh4JuTf3B/yDQArPXV57OijpE82gPkF+2mpdpFzpyIiImXeLzuPnFJCqhvpvB36FhfbdgLwdv7tvJ7fmfy//LV5YVwkF1dxlFpWkWCjIiIiZd7JEtKhSRVe6XIJxtpp2L8ajuE6hhl1Ae4O43moVmseOs1r7YaBzWaUbmCRIKIiIiJl3ski4gh1E/pVf/jFe68Yql2N0el9QmIrW5hOJLipiIhImXc8z00tYy99tzwDx7cBBlz3FFz7FNj116SIL+lPmIiUeXX3fcmAsNFEHXdCuYrQ6T2o2dLqWCJlgoqIiJRdrhz4+kk675oMBuwp35ykB/8NMZWsTiZSZqiIiEjZtH89TO0GBzfhwcbreXdQ6fKnuU8lRKRUaYl3ESlbTNN7Mep7reDgJoipTGrFlxnjvoOIcN2wTqS0qYiISNnhzIbpD8HsRyH/BNRqDb1/YLXtYkALk4lYQVMzIhI0TuS5+eCH7Rw85jzluUq5m+m87VkucO7Cg51vL+zFUsd98O1+th/MASBSRUSk1KmIiEjQmLduH6/M2/SXrSb32hfSPeRjwo080sx4HnU9yqqtF8HWXYX2TIjW1IxIaVMREZGgcTjHBUCditHceHElwvKP0XZbKvUOee8Vs6X81cytNYwrQx1c+ZfXVo2P4uIqsaWcWERUREQkaJxcIbVJchxPNjoOU3vCke1gC4E2I6id0pdHDS3HLuJPVEREJGgcd7kBk1aZ0+GDd8DtAkdV6DIRkppZHU9ETkNFRESChif3COND3+CmPSu9G+rdCu3HQmR5a4OJyN9SERGR4LDnZ3qu70a8PR23EYK97Ui44mHQVIyIX9M6IiIS2EwTfhwLH7YlPi+dnZ6KfNlsElzZWyVEJACoiIhI4Mo9DJ/eDfP/CZ58fi53Hbe6XiTngsZWJxORItLUjIgEpl0rYNqDkLUH7OFw04u8sboh2YcOaYVUkQCiIiIifsmZ7+ZEnufUJ0wPYSvGErFkJIbpxl2+JrntP8BTqRHZP/0EQGSo/moTCRT60yoifmfjviw6vfMjOX+uC3JSPFm8FjqOlvY1AMx0t+Cf6T3IGZ8OpBfspzMiIoFDRURE/M4vO4+eUkKaGxt4K2wsicYRTpihDMvvxufulkDhC1IrOyJoeKGj9MKKyHlRERERv5Prygfg1saVeb1LI2xLX8e2OBXD9GBWqIu980RGVmzAyNO81m4Y2Gz6toxIoFARERG/c/zPsyGJtixCP+0M2xZ5n7jkHoxbRhMaVs66cCJSolRERMTv5Oa5SbGtY8CWcZB/GEKj4JZXock9VkcTkRKmIiIi/sXj5oodE3gydCK2fBMqNoDOE6FiPauTiYgPaEEzEfEfWenwf+1pue9DbIbJusQO0HOhSohIECuVIvL2229TvXp1IiIiuOKKK/jpz+/6i4gU2PINjL8adnzPCSOSx1x9+anRcxAWZXUyEfEhnxeRzz77jIEDBzJ8+HB++eUXLrnkEtq2bcuBAwd8fWgRCQTufPhmBPy7E+QehEqNGFFlHLM9V2k9EJEywOdF5LXXXqNXr150796dBg0aMH78eKKiovjwww99fWgR8XeZe+GjW+GH17zjZj2g5zdsNxMBiAzTZWwiwc6nf8pdLherVq1i6NChBdtsNhtt2rRh2bJlp+zvdDpxOp0F46ysLF/GExEf+23PUWatTsNjmqc8VydzKR22v0CUO5MTtnJ8WW0I683W8J+tbM3IASAqVGdERIKdT4vIwYMHcbvdVKpUqdD2SpUqsXHjxlP2T01NZcSIEb6MJCKl6NlZ61iz+2ihbSHk82TIZ9wT8hUAv3lq0M/5GLs2VAJ2FNr3gpjw0gkqIpbxq/OeQ4cOZeDAgQXjrKwskpOTLUwkIufjcI73DGfnpklUig0n1pnObX88Q5VjawFYlXgni6s9ym22sFNem1Q+ikuStFS7SLDzaRG54IILsNvt7N+/v9D2/fv3k5iYeMr+4eHhhIfrX0AiweLkCqk9rq5B/czvYWYfOJEJEQ5o/zZN699GU4szioi1fHqxalhYGE2bNmXhwoUF2zweDwsXLiQlJcWXhxYRP5DrchNKPhcuHwFT7vGWkAubwsPfQ/3brI4nIn7A51MzAwcOpGvXrjRr1ozmzZvzxhtvkJOTQ/fu3X19aBGxkGmaXJCXxpiwMcSu2ebdmNIPWg+HkFOnYkSkbPJ5EbnrrrvIyMhg2LBh7Nu3jyZNmvCf//znlAtYRSS45P0+gzlhTxNrHMeMKI/RcRxc1M7qWCLiZwzTPM336vxEVlYWDoeDzMxMYmNjrY4jIkWRdwLm/xNWvg/Az566XPr4dOzldeG5SFlRnM9vv/rWjIgEuENbYWpX2Pc7AO/k385Y7mS9SoiI/A0VEREpGb9Pgy/7g+sYRFVgb6s3ePkLO3FRoVYnExE/piIiIkWSfSIPz+kmcvOOE7nwacLWfAxAfnIKube9y87sKGCFVkcVkTNSERGRsxrx5TomLt1xyvZaxl7Ghr5FfdtuPKbBGHcH3tp8B+7Xfi/YJ1I3rhORM1AREZGz+n7zwVO23WFbwguhE4kynGSYDgbkPcJST6NT9mvTQN+QE5G/pyIiImd1coXUL/qk0LhiKPb/PIVtzScAeKpfS1zHd5kUfWrhMIAQu89v8i0iAUxFRETOKteVD0CF3G2EftgXMjaCYYOWQ7Fd8wQ2m6ZfROTcqIiIyFnluvLpYl9E1S/+D/JPQHQidHofalxjdTQRCXAqIiJyRu7jWYwyxtIxZCnkA7Wuh47vQnSC1dFEJAioiIjI39v3O8bnXelo30q+acNs9Qyh1z4ONl33ISIlQ3+biMipTBN+/hDea43t8FbSzHj+kfcMIdcNVAkRkRKlMyIiUtiJLPjyMVg3A4Dc6m24eWMXXGFxGIZhcTgRCTYqIiLyX2mrYWo3OLIdbCHQ5jl2Vr+foxuXcoEWJhMRH1ARESlDft+TyczVe/H89abbpsnlGV9w454xhJh5HA1LZFqN59l7qCEZO7YBWiFVRHxDRUSkDHnuy3Ws2nmk0LZYcngp9F3a2VcCMM/djCezHiJrTTSwo2C/C6LDSzGpiJQVKiIiZcjhHBcAd1x2IZUdESRmr+O2zcOIc6bjNkJYVO0xfku8k/v/ci2IzTC4uVFlKyKLSJBTEREpQ06ukPpgi+o03D0ZVgwHTx6Ur46980RaX3gZrS3OKCJli4qISBmS63Lj4Bg1vukJOxZ4NzZoD7ePgQiHteFEpExSEREpQ+rnb+D18Lcot+MQ2MPhphehWQ/Q13JFxCIqIiJlgceDe+mbfGJ/nhDDg7t8Tex3fgSVG1udTETKOBURkWCXcxBm9Ma+ZQEYMMvdgnY9p2Avp6kYEbGeiohIMNuxFL7oAdnpmPYIhpy4n2lmK26PirU6mYgIoHvNiAQnjweWvAIf3QrZ6XBBXfZ0mcNn7lZEhYZoqXYR8Rs6IyISoLJP5OExT91u5Bwgcs4jhO5YBICr4V0cv+El0g+bwAGtkCoifkVFRCQAjfxqPe99v/2U7Sm2dbwZ+jaxxlFyzXCG5Xdj2s/Xwc8/FuwTpSIiIn5ERUQkAH2/+WChsQ0Pj4VM5zH7DGyGySZPEn3zHmOLmXTKa29oUKm0YoqInJWKiEgAynW5AfjsoSu5LP4E9hkPYdv5AwCeJvdT86ZRzA2NOu1rQ+26NExE/IeKiEgAOllEEg/+SOi0AZB7EELLwW1vYGt8p65CF5GAoSIiEoBcLieDQj6j6tezARMqNYIuk+CC2lZHExEpFhURkQBjZu7hA0Zwecgm74ZmD0LbFyE00tpgIiLnQEVEJJD8MR9mPMzltsNkm5GEdBhD5KVdrE4lInLOfDaVPHLkSFq0aEFUVBRxcXG+OoxI2eDOg/nPwiddMI4f5ndPdW5xvUjYJZ2tTiYicl58VkRcLhddunShT58+vjqESNlwdBdMbAc/vgVA9iU96OQawT57Zew2rZAqIoHNZ1MzI0aMAGDSpEm+OoRI8Nv4Fcx8BE4chXAHtB/LvgqtcK1YQpwWJhORIOBX14g4nU6cTmfBOCsry8I0Ir63dm8mM3/di9ssvFa7zZPHDXvf4coDnwGwJ6oBX9R8nqNbq3BozRYAokJVREQk8PlVEUlNTS04kyJSFjw/Zz0/bT9caFuScYCxoW/RxLYNgPfyb+blw3eTd9gF7CjY74KY8FJMKiLiG8UqIkOGDOGll1464z4bNmygXr165xRm6NChDBw4sGCclZVFcnLyOf0skUBwOMcFQMdLL6RKXAR1D31L260jiXAf47g9lrm1h3E0/hoe+svrbIbBTQ0TSz+wiEgJK1YReeKJJ+jWrdsZ96lZs+Y5hwkPDyc8XP/Kk7Lj+J8rpHZrnsgl60fDH+95n0i+gshOH3BHnIq4iAS3YhWRhIQEEhISfJVFpMzJdeVT3Ujnoq86wcG13o1XDYDrnwF7qKXZRERKg8+uEdm1axeHDx9m165duN1uVq9eDUDt2rWJjo721WFFAkqr/O8ZEfYeEQePQ1QF6Pgu1GljdSwRkVLjsyIybNgwPvroo4LxpZdeCsB3331Hy5YtfXVYkcCQdxxz7hBes03yDpNSCL3zQ4itYm0uEZFSZpjmX7436EeysrJwOBxkZmYSGxtrdRyRkpHxB0ztBgfW4TENxrrb0+uZd4mM0PVRIhIcivP57Vdf3xUJemumwJyBkJeDJ+oC7j/ai6WeRvQLC7M6mYiIJXy2xLuI/A9XDszsCzMehrwcqHEtaXd/w1JPIyJD7di0VLuIlFE6IyJSAvLcHnL//CruX9kyNhI1qwf2Q5swDRvOq57EmTKQ/QdzAYjSUu0iUoapiIicpyM5Lm54fQkHjzn/8oxJF/ting+ZhN1wsd+Mo7+rH8u/aQDfLCzYK1JFRETKMBURkfO0YV/WKSUkihO8EPohd9h/AGCJuxGP5z3CIRynvP6GBpVKJaeIiD9SERE5TydXR210oYPpj7SA/WsJmdYd4/AWTMOOp+XTpFw1gOXG6S/JCrXrUi0RKbtURETO08lrQ6JCbYT+OgnmDgG3E2KqYHT+EHu1FDT5IiJyeioiIufpuMtNNLkMzHoX5izybqxzI3QYD+UqWJpNRMTfqYiInKeIg7/zZdg/qZG7H2wh0Ho4pPQDm6ZcRETORkVE5FyZJvz0Hrf89DR2Wx5HQitR/oHJkHy51clERAKG/skmci6OH4XPH4C5T2I385jvbsqEepNUQkREiklFRKS49q6CCdfChtlgC+U/SQN4KG8gRMVbnUxEJOBoakakqEwTlo+DBcPAkwdx1aDLRBavCAV2a4VUEZFzoCIi8ifTNPm/ZTvZcSjnlOci8rNov+MF6mV6FyhbH9eS2dWG4vwlgp+2ZwBaql1E5FyoiIj8aX16FsNnrztl+2XGH7wVNpYk4yBOM4R/5d/Pv/e1gX2HgEMF+10QHV6KaUVEgoOKiMifDue4ALggOoy7Lk8G00PztMlcs2scNtwciUhidt0XcZS7iL5/eW18uXBuaphY+qFFRAKciojIn06ukJocH8WTVyfAjIdh1wLvkw07Uf7WN+gaEWthQhGR4KMiIvKnk/eMudRcD+N7QnYahERAu5fgsq5gGBYnFBEJPioiIn/KdebR1z6TJzKmAR6oUAe6TILEhlZHExEJWioiIgDHDnDtTw+TFLrcO258N9zyKoRHW5tLRCTIaUEzke1LYPzVJB1eznEzjKlJQ+GOCSohIiKlQGdEpOzyuGHJK7D4JTA9ZETW5B9He3NNpautTiYiUmaoiEjZlL0PvugJO773ji+9j3fNB9myfB9ttTCZiEipKZNFJM/tKfiqppQ9IdsXETmnD7bcDMzQchxv+wp5F9/JwT8XM4sKK5N/LERELFEm/8ZdtvUQD3z4k9UxpJTZcTMg5Av62mdhM0w2eKrS99hjbJsWB9PmF+wXGaozIiIipaVMFhEpexI5xJthb3OFbSMAk/Nb83z+/TgJK7RfbEQIzWvoLroiIqXFME3TtDrE38nKysLhcJCZmUlsbMmtaOnxmLj9921LCTM2z8c+qw/G8cOYYTG4b30D8+I7Truv3TCw2bRwmYjI+SjO53eZPCNisxnY0IdN0HPnwcLn4ce3vOPKl2B0nkhIhVrW5hIRkQJlsohIGXB0N0x7EPb8eS1Q84fhxn9BiO6QKyLiT1REJPhs/Bpm9oETRyHcAe3HQoPbrU4lIiKnoSIiwSPfBd88B8vf9o6rXAZdJkL56lamEhGRM/DZEu87duygR48e1KhRg8jISGrVqsXw4cNxuVy+OqSUZUd2wIdt/1tCruwLD85TCRER8XM+OyOyceNGPB4PEyZMoHbt2qxdu5ZevXqRk5PD6NGjfXVYKYvWz4ZZ/cCZCRFx0GEc1LvZ6lQiIlIEpfr13VdeeYVx48axbdu2Iu3vq6/vSpDId8L8Z+Cnd73jpObQ+UOIS7Y2l4hIGee3X9/NzMwkPv7vF4tyOp04nc6CcVZWVmnEkkB0aCtM6w7pa7zjq/rD9c+CPdTaXCIiUiw+u0bkr7Zs2cKYMWN4+OGH/3af1NRUHA5HwSM5Wf+yldNY+wVMuM5bQiLj4Z6pcMPzKiEiIgGo2EVkyJAhGIZxxsfGjRsLvWbv3r3cdNNNdOnShV69ev3tzx46dCiZmZkFj927dxf/HUnwyjsOXw7wrg/iyoaqLaD3D1D3RquTiYjIOSr2NSIZGRkcOnTojPvUrFmTsDDvPTzS0tJo2bIlV155JZMmTcJmK3r30TUiUuDgZpjaDfavBQy4dhBcNwTs+ga6iIi/8ek1IgkJCSQkJBRp371799KqVSuaNm3KxIkTi1VCRAqs+QzmPA55OVAuAe54F2pdb3UqEREpAT775+TevXtp2bIl1apVY/To0WRkZBQ8l5iY6KvDSjBx5cLcJ+HXf3vH1a+BTu9DjH7/iIgEC58VkQULFrBlyxa2bNlCUlJSoef8+Ia/4i8ObISpXSFjI2BAyyFw7ZNgs1udTERESlCpriNSXLpGpAwyTVg9Gb4aBPnHIbqS9yxIjWutTiYiIkXkt+uIiJyR8xh89QT8NsU7rtkK7ngPoot2TZKIiAQeFRHxD/vWehcoO/gHGDZo9U+4eiDoAmcRkaCmIiLWMk1YNQn+MwTyT0BMFej8AVRrYXUyEREpBSoiYp0TWTBngHelVIDaN0DHCVCugqWxRESk9KiIiDXS13gXKDu8DWwh0HoYpDyqqRgRkTJGRURKl2nCyvdh3tPgdoEj2XvH3OTmVicTERELqIhI6Tl+FL58DNbP8o4vuhnavw1Rf39HZhERCW4qIlI69q6Cqd3h6E6whXrvlntlHzAMq5OJiIiFVETEt0wTlo+DBcPAkwdx1aDLRLiwqdXJRETED6iIiO/kHoZZ/WDTV95x/dvh9jEQGWdpLBER8R8qIuIbu1d6FyjL3A32MGj7IlzeU1MxIiJSiIqIlCyPB5aNgYXPgycfyteALpOgShOrk4mIiB9SEZGSk3MIZvaBzfO844vvgNvehAjdsFBERE5PRURKxs4fYVoPyE4Dezi0ewmadtNUjIiInJGKiJwfjwd+eA2+exFMN1So452KSWxodTIREQkAKiJy7o5lwIyHYOu33nHju+GWVyE82tpcIiISMFRE5Nxs/x6+6AnH9kFIJNwyGprcq6kYEREpFhURKR6PG5a8AotfAtMDCfW8UzEV61udTEREApCKiBRd9n6Y3hO2L/GOL70P2r0CYVHW5hIRkYClIiJFs/U7mN4LcjIgtBzc+hpccrfVqUREJMCpiMiZufNhUSp8/ypgQsWLvVMxCXWtTiYiIkFARUT+Xlaa94LUnUu946bd4aZUCI20NpeIiAQNFRE5vc0LYMbDkHsIwmLgtjegUWerU4mISJBREZHC3Hnw7b9g6ZvecWJj71RMhVqWxhIRkeCkIiL/dXQ3fNEDdq/wjps/BDf8C0IjrM0lIiJBS0VEvDbNhRm94cRRCHdA+zHQoL3VqUREJMipiJR1+S5YOAKWjfWOq1wGnT+E+BrW5hIRkTJBRaQsO7IDpj0Ie1d5x1c+Am1GQEiYpbFERKTsUBEpq9bPhln9wJkJEXHQYRzUu9nqVCIiUsaoiJQ1+U6Y/wz89K53nHS5dyomrqq1uUREpExSESlLDm2Fad0hfY13fFV/uP5ZsIdam0tERMosmy9/+O23307VqlWJiIigcuXK3H///aSlpfnykPJ31k6HCdd5S0hkPNwzFW54XiVEREQs5dMi0qpVKz7//HM2bdrEF198wdatW+ncWatzlqq84zDnce+ZEFc2VE2B3j9A3RutTiYiIoJhmqZZWgebPXs2HTp0wOl0Ehp69n+JZ2Vl4XA4yMzMJDY2thQSBpmDm2FqN9i/FjDgmieg5VCwa0ZORER8pzif36X2iXT48GEmT55MixYt/raEOJ1OnE5nwTgrK6u04gWf3z6HLwdAXg5EXQCd3oNa11udSkREpBCfTs0ADB48mHLlylGhQgV27drFrFmz/nbf1NRUHA5HwSM5OdnX8YKPK9f7tdzpvbwlpPo10GepSoiIiPilYheRIUOGYBjGGR8bN24s2P/JJ5/k119/Zf78+djtdh544AH+bjZo6NChZGZmFjx279597u+sLDqwEd67Hn79GDDguiHwwCyISbQ6mYiIyGkV+xqRjIwMDh06dMZ9atasSVjYqatz7tmzh+TkZH788UdSUlLOeixdI1IMv06GrwdBXi5EV4I73oOa11mdSkREyiCfXiOSkJBAQkLCOQXzeDwAha4DkfPkPOYtIGs+9Y5rtoI73oXoitbmEhERKQKfXay6YsUKVq5cydVXX0358uXZunUrzz77LLVq1SrS2RApgv3rvN+KOfgHGDZo9TRc/QTYfH7pj4iISInw2SdWVFQU06dPp3Xr1lx00UX06NGDxo0bs3jxYsLDw3112LLBNGHVJO/1IAf/gJjK0HUOXPukSoiIiAQUn50RadSoEd9++62vfnzZ5cz2fi137TTvuPYN0HE8lLvA0lgiIiLnQitbBZL0Nd6pmMPbwLBD62HQ4jGdBRERkYClIhIITBNWvg/znga3C2KTvHfMrXqF1clERETOi4qIvzuRCbMfhfV/LgR30c3Q/m2Iirc2l4iISAlQEfFne3/xTsUc3Qm2ULhhBFz5CBiG1clERERKhIqIPzJNWDEe5j8LnjyIqwqdJ0FSU6uTiYiIlCgVEX9z/Ij3XjEb53jH9W+D28dCZJylsURERHxBRcSf7F4J0x6EzF1gD4MbR0LzXpqKERGRoKUi4g88Hlg2FhaOAE8+lK8BXSZBlSZWJxMREfEpFRGr5R6GGb1h8zzv+OI74LY3IUI3+RMRkeCnImKlncvgix6QtRfs4dBuFDTtrqkYEREpM1RErODxwNLX4duRYLqhQm3vVExiI6uTiYiIlCoVkdJ2LANmPARb/7wPT+O74JbXIDza2lwiIiIWUBEpTdu/hy96wrF9EBIJN78Cl96nqRgRESmzVERKg8cNS0bD4lFgeiChnncqpmJ9q5OJiIhYSkXE17L3w/SesH2Jd9zkPrj5ZQgrZ20uERERP6Ai4ktbv4PpD0HOAQgtB7e+BpfcbXUqERERv6Ei4gvufO80zJLRgAkVL/ZOxSTUtTqZiIiIX1ERKWlZad4LUncu9Y6bdoObRkFopKWxRERE/JGKSEna/I33q7m5hyAs2rtCaqPOVqcSERHxWyoiJcGdB9+NhB9e944TG0GXj6BCLWtziYiI+DkVkfOVucd7x9zdK7zjy3vBjS9AaIS1uURERAKAisj52DQXZvaB40cgPBZuHwMXd7A6lYiISMBQETkX+S5YOAKWjfWOq1wKnSdCfA1rc4mIiAQYFZHiOrITpnWHvau84ysfgTYjICTM2lwiIiIBSEWkODZ8CbP6wolMiHBAh3FQ7xarU4mIiAQsFZGiyHfC/GfhpwnecdLl0PlDiKtqbS4REZEApyJyNoe3wdTukL7aO27xGLQeBvZQS2OJiIgEAxWRM1k3A2Y/Bs4siIyHjuOhblurU4mIiAQNFZHTyTsB856Gnz/wjqumQKcPwHGhtblERESCjIrIXx3cAlO7wf7fveOrB0Krf4Jd/6tERERKmj5d/9dvU2HOAHAdg6gL4I4JULuN1alERESClq00DuJ0OmnSpAmGYbB69erSOGTxuHJhVj+Y3tNbQqpfA71/UAkRERHxsVIpIk899RRVqlQpjUMVX8YmeL81/PoxYMB1Q+CBWRBb2epkIiIiQc/nRWTu3LnMnz+f0aNH+/pQxbf6E3i3JRxYD9GVvAWk1VCw2a1OJiIiUib49BqR/fv306tXL2bOnElUVNRZ93c6nTidzoJxVlaWb4K5cuCrJ2DNp95xzZZwx3sQXdE3xxMREZHT8tkZEdM06datG71796ZZs2ZFek1qaioOh6PgkZyc7JtwP0/0lhDDBtc/A/dNVwkRERGxQLGLyJAhQzAM44yPjRs3MmbMGLKzsxk6dGiRf/bQoUPJzMwseOzevbu48Yrmit5w8R3QdQ5c+6SmYkRERCximKZpFucFGRkZHDp06Iz71KxZkzvvvJMvv/wSwzAKtrvdbux2O/feey8fffTRWY+VlZWFw+EgMzOT2NjY4sQUERERixTn87vYRaSodu3aVegaj7S0NNq2bcu0adO44oorSEpKOuvPUBEREREJPMX5/PbZxapVqxa+M210dDQAtWrVKlIJERERkeBXKuuIiIiIiJxOqS3xXr16dXw0CyQiIiIBSmdERERExDIqIiIiImIZFRERERGxjIqIiIiIWEZFRERERCyjIiIiIiKWURERERERy6iIiIiIiGVURERERMQypbay6rk4uRLr/948T0RERPzbyc/toqyo7tdFJDs7G4Dk5GSLk4iIiEhxZWdn43A4zriPYfrxDWA8Hg9paWnExMRgGEaJ/uysrCySk5PZvXv3WW9RHIj0/gJfsL/HYH9/EPzvUe8v8PnqPZqmSXZ2NlWqVMFmO/NVIH59RsRms5GUlOTTY8TGxgbtbzDQ+wsGwf4eg/39QfC/R72/wOeL93i2MyEn6WJVERERsYyKiIiIiFimzBaR8PBwhg8fTnh4uNVRfELvL/AF+3sM9vcHwf8e9f4Cnz+8R7++WFVERESCW5k9IyIiIiLWUxERERERy6iIiIiIiGVURERERMQyKiL/w+l00qRJEwzDYPXq1VbHKTG33347VatWJSIigsqVK3P//feTlpZmdawSs2PHDnr06EGNGjWIjIykVq1aDB8+HJfLZXW0EjNy5EhatGhBVFQUcXFxVscpEW+//TbVq1cnIiKCK664gp9++snqSCVmyZIl3HbbbVSpUgXDMJg5c6bVkUpUamoql19+OTExMVSsWJEOHTqwadMmq2OVmHHjxtG4ceOCRb5SUlKYO3eu1bF8ZtSoURiGwYABAyw5vorI/3jqqaeoUqWK1TFKXKtWrfj888/ZtGkTX3zxBVu3bqVz585WxyoxGzduxOPxMGHCBNatW8frr7/O+PHjefrpp62OVmJcLhddunShT58+VkcpEZ999hkDBw5k+PDh/PLLL1xyySW0bduWAwcOWB2tROTk5HDJJZfw9ttvWx3FJxYvXkzfvn1Zvnw5CxYsIC8vjxtvvJGcnByro5WIpKQkRo0axapVq/j555+5/vrrad++PevWrbM6WolbuXIlEyZMoHHjxtaFMMU0TdP8+uuvzXr16pnr1q0zAfPXX3+1OpLPzJo1yzQMw3S5XFZH8ZmXX37ZrFGjhtUxStzEiRNNh8NhdYzz1rx5c7Nv374FY7fbbVapUsVMTU21MJVvAOaMGTOsjuFTBw4cMAFz8eLFVkfxmfLly5vvv/++1TFKVHZ2tlmnTh1zwYIF5nXXXWf279/fkhw6IwLs37+fXr168fHHHxMVFWV1HJ86fPgwkydPpkWLFoSGhlodx2cyMzOJj4+3OoachsvlYtWqVbRp06Zgm81mo02bNixbtszCZHKuMjMzAYLyz5zb7WbKlCnk5OSQkpJidZwS1bdvX2655ZZCfxatUOaLiGmadOvWjd69e9OsWTOr4/jM4MGDKVeuHBUqVGDXrl3MmjXL6kg+s2XLFsaMGcPDDz9sdRQ5jYMHD+J2u6lUqVKh7ZUqVWLfvn0WpZJz5fF4GDBgAFdddRUNGza0Ok6J+f3334mOjiY8PJzevXszY8YMGjRoYHWsEjNlyhR++eUXUlNTrY4SvEVkyJAhGIZxxsfGjRsZM2YM2dnZDB061OrIxVLU93fSk08+ya+//sr8+fOx2+088MADmH6+qG5x3yPA3r17uemmm+jSpQu9evWyKHnRnMv7E/E3ffv2Ze3atUyZMsXqKCXqoosuYvXq1axYsYI+ffrQtWtX1q9fb3WsErF792769+/P5MmTiYiIsDpO8C7xnpGRwaFDh864T82aNbnzzjv58ssvMQyjYLvb7cZut3Pvvffy0Ucf+TrqOSnq+wsLCztl+549e0hOTubHH3/061ONxX2PaWlptGzZkiuvvJJJkyZhs/l3zz6XX8NJkyYxYMAAjh496uN0vuNyuYiKimLatGl06NChYHvXrl05evRo0J2tMwyDGTNmFHqvwaJfv37MmjWLJUuWUKNGDavj+FSbNm2oVasWEyZMsDrKeZs5cyYdO3bEbrcXbHO73RiGgc1mw+l0FnrO10JK7UilLCEhgYSEhLPu99Zbb/HCCy8UjNPS0mjbti2fffYZV1xxhS8jnpeivr/T8Xg8gPfryv6sOO9x7969tGrViqZNmzJx4kS/LyFwfr+GgSwsLIymTZuycOHCgg9nj8fDwoUL6devn7XhpEhM0+TRRx9lxowZLFq0KOhLCHh/j/r735lF1bp1a37//fdC27p37069evUYPHhwqZYQCOIiUlRVq1YtNI6OjgagVq1aJCUlWRGpRK1YsYKVK1dy9dVXU758ebZu3cqzzz5LrVq1/PpsSHHs3buXli1bUq1aNUaPHk1GRkbBc4mJiRYmKzm7du3i8OHD7Nq1C7fbXbDOTe3atQt+zwaSgQMH0rVrV5o1a0bz5s154403yMnJoXv37lZHKxHHjh1jy5YtBePt27ezevVq4uPjT/k7JxD17duXTz75hFmzZhETE1NwbY/D4SAyMtLidOdv6NChtGvXjqpVq5Kdnc0nn3zCokWLmDdvntXRSkRMTMwp1/OcvIbQkut8LPmujh/bvn17UH1997fffjNbtWplxsfHm+Hh4Wb16tXN3r17m3v27LE6WomZOHGiCZz2ESy6du162vf33XffWR3tnI0ZM8asWrWqGRYWZjZv3txcvny51ZFKzHfffXfaX6+uXbtaHa1E/N2ft4kTJ1odrUQ8+OCDZrVq1cywsDAzISHBbN26tTl//nyrY/mUlV/fDdprRERERMT/+f9EuoiIiAQtFRERERGxjIqIiIiIWEZFRERERCyjIiIiIiKWURERERERy6iIiIiIiGVURERERMQyKiIiIiJiGRURERERsYyKiIiIiFhGRUREREQs8//rZJkxpwrmGgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(-4,4,1000), quantized_bits(4,1,1,alpha=1)(np.linspace(-4,4,1000)))\n",
    "plt.plot(np.linspace(-4,4,1000), np.linspace(-4,4,1000))\n",
    "\n",
    "plt.legend([\"Quantized\", \"Floating\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbda795-2b0a-4938-aa46-d953ae714644",
   "metadata": {},
   "source": [
    "## Creating a quantized model\n",
    "\n",
    "Using the `QDense` layer.\n",
    "\n",
    "Requires setting `kernel_quantizer` and `bias_quantizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dc143510-e4a5-4af8-b7ea-39dac9eeb67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc1 (QDense)                (None, 32)                544       \n",
      "                                                                 \n",
      " relu1 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " fc2 (QDense)                (None, 32)                1056      \n",
      "                                                                 \n",
      " relu2 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " fc3 (QDense)                (None, 32)                1056      \n",
      "                                                                 \n",
      " relu3 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " output (QDense)             (None, 5)                 165       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2821 (11.02 KB)\n",
      "Trainable params: 2821 (11.02 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qmodel = Sequential()\n",
    "qmodel.add(QDense(32, input_shape=(16,),\n",
    "                  name='fc1',\n",
    "                  kernel_quantizer = quantized_bits(4,1,1,alpha=1),\n",
    "                  bias_quantizer = quantized_bits(4,1,1,alpha=1),\n",
    "                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "qmodel.add(Activation(activation='relu', name='relu1'))\n",
    "qmodel.add(QDense(32, \n",
    "                  name='fc2', \n",
    "                  kernel_quantizer = quantized_bits(4,1,1,alpha=1),\n",
    "                  bias_quantizer = quantized_bits(4,1,1,alpha=1),                  \n",
    "                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "qmodel.add(Activation(activation='relu', name='relu2'))\n",
    "qmodel.add(QDense(32, \n",
    "                  name='fc3', \n",
    "                  kernel_quantizer = quantized_bits(4,1,1,alpha=1),\n",
    "                  bias_quantizer = quantized_bits(4,1,1,alpha=1),                  \n",
    "                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "qmodel.add(Activation(activation='relu', name='relu3'))\n",
    "qmodel.add(QDense(5, \n",
    "                  name='output', \n",
    "                  kernel_quantizer = quantized_bits(4,1,1,alpha=1),\n",
    "                  bias_quantizer = quantized_bits(4,1,1,alpha=1),                  \n",
    "                  kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "qmodel.add(Activation(activation='softmax', name='softmax'))\n",
    "\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b8a9ec3c-ccd7-46fa-8ebc-6da6241f7ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.8152 - accuracy: 0.7306 - val_loss: 0.7713 - val_accuracy: 0.7454\n",
      "Epoch 2/2\n",
      "3891/3891 [==============================] - 15s 4ms/step - loss: 0.7935 - accuracy: 0.7355 - val_loss: 0.7687 - val_accuracy: 0.7445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x75d3191b3d90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "qmodel.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "qmodel.set_weights(model.get_weights())\n",
    "\n",
    "qmodel.fit(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    batch_size=128,\n",
    "    epochs=2,\n",
    "    validation_split=0.25,\n",
    "    shuffle=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6be343af-7593-474e-b0b8-3092bcf79b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "-----------------------------------\n",
      "Configuration\n",
      "{'Model': {'Precision': {'default': 'fixed<16,6>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'BramFactor': 1000000000, 'TraceOutput': False}, 'LayerName': {'fc1_input': {'Trace': False, 'Precision': {'result': 'auto'}}, 'fc1': {'Trace': False, 'Precision': {'result': 'auto', 'weight': 'fixed<4,2,TRN,WRAP,0>', 'bias': 'fixed<4,2,TRN,WRAP,0>', 'accum': 'auto'}, 'ReuseFactor': 1}, 'fc1_linear': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'relu1': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'fc2': {'Trace': False, 'Precision': {'result': 'auto', 'weight': 'fixed<4,2,TRN,WRAP,0>', 'bias': 'fixed<4,2,TRN,WRAP,0>', 'accum': 'auto'}, 'ReuseFactor': 1}, 'fc2_linear': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'relu2': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'fc3': {'Trace': False, 'Precision': {'result': 'auto', 'weight': 'fixed<4,2,TRN,WRAP,0>', 'bias': 'fixed<4,2,TRN,WRAP,0>', 'accum': 'auto'}, 'ReuseFactor': 1}, 'fc3_linear': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'relu3': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'output': {'Trace': False, 'Precision': {'result': 'auto', 'weight': 'fixed<4,2,TRN,WRAP,0>', 'bias': 'fixed<4,2,TRN,WRAP,0>', 'accum': 'auto'}, 'ReuseFactor': 1}, 'output_linear': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>'}, 'ReuseFactor': 1, 'TableSize': 1024}, 'softmax': {'Trace': False, 'Precision': {'result': 'auto', 'table': 'fixed<18,8,TRN,WRAP,0>', 'exp_table': 'fixed<18,8,RND,SAT,0>', 'inv_table': 'fixed<18,8,RND,SAT,0>'}, 'ReuseFactor': 1, 'TableSize': 1024, 'Implementation': 'stable', 'Skip': False}}}\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lauri/miniconda3/envs/oneapi-env/lib/python3.10/site-packages/keras/src/constraints.py:365: UserWarning: The `keras.constraints.serialize()` API should only be used for objects of type `keras.constraints.Constraint`. Found an instance of type <class 'qkeras.quantizers.quantized_bits'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(qmodel, granularity='name', backend='oneAPI')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "print(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    qmodel, hls_config=config, backend='oneAPI', output_dir='model_2/hls4ml_prj', part='Agilex7'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5a6bd5de-df16-456c-a176-02ae17944016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "/opt/intel/oneapi/2025.0/bin/icpx\n",
      "-- The CXX compiler identification is IntelLLVM 2025.0.4\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /opt/intel/oneapi/2025.0/bin/icpx - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.6s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/lauri/local/icl/notebooks/model_2/hls4ml_prj/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/myproject_bridge.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libmyproject-974ccfb0.so\u001b[0m\n",
      "[100%] Built target lib\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)\n",
    "\n",
    "hls_accuracy = np.sum(np.argmax(y_test, axis=1) == np.argmax(y_hls, axis=1))/y_test.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a2266dc0-9132-45d5-8100-3fa2f4cba4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved test accuracy of 74.31%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Achieved test accuracy of {(100 * hls_accuracy):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "54fcca54-e397-4d9c-8b3a-57b353abfd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/2025.0/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/lauri/local/icl/notebooks/model_2/hls4ml_prj/build\n",
      "[ 25%] \u001b[34m\u001b[1mTo compile manually:\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -I../src -I../src/firmware -fsycl -fintelfpga -Wall -qactypes -Wno-unused-label -fconstexpr-steps=134217728 -DFPGA_HARDWARE -c ../src/firmware/myproject.cpp -o CMakeFiles/report.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -I../src -I../src/firmware -fsycl -fintelfpga -Wall -qactypes -Wno-unused-label -fconstexpr-steps=134217728 -DFPGA_HARDWARE -c ../src/myproject_test.cpp -o CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "\u001b[34m\u001b[1m\u001b[0m\n",
      "\u001b[34m\u001b[1mTo link manually:\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -fsycl -fintelfpga -Wno-unused-label -fconstexpr-steps=134217728 -Xshardware -Xstarget=Agilex7 -Wno-unused-label -fsycl-link=early -o myproject.report CMakeFiles/report.dir/src/firmware/myproject.cpp.o CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "[ 25%] Built target displayReportCompileCommands\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/report.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable myproject.report\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation fault (core dumped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Built target report\n",
      "['ALUTs ', 'FFs  ', 'RAMs ', 'DSPs ', 'MLABs', 'Frac. DSPs']\n",
      "['974400', '1948800', '7110', '4510', '24360', '0']\n",
      "[34657, 38922, 8, 0, 23, 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hls_model.build(build_type='report')\n",
    "with open(\"model_2/hls4ml_prj/build/myproject.report.prj/reports/resources/json/summary.ndjson\", \"r\") as f:\n",
    "    summary = ndjson.load(f)\n",
    "\n",
    "resource_names = list(filter(lambda x: x[\"name\"] == \"Estimated Resource Usage\", summary))[0]['columns'][1:]\n",
    "available = list(filter(lambda x: x[\"name\"] == \"Available\", summary))[0]['data']\n",
    "estimated_resources = list(filter(lambda x: x[\"name\"] == \"Total\", summary))[0]['data']\n",
    "\n",
    "print(resource_names)\n",
    "print(available)\n",
    "print(estimated_resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff4d52-a7dc-4ace-9321-27a08833b1fe",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "See how low bitwidth can still have the same accuracy as the baseline model.\n",
    "\n",
    "Loop over several bitwidths and plot the accuracy and resource usage as a function of bitwidth.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b45f2-55e6-461e-94d1-da1baa2ae801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bcec4df-060c-4650-9f70-e9f3e6e23dca",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "\n",
    "Weight matrices in NNs can be huge, but not every weight contributes equally to the model performance.\n",
    "\n",
    "Low magnitude weights can be pruned out with very small impact to the performance.\n",
    "\n",
    "On FPGAs the weight matrices are known at compile time. Weights that are zero can be omitted by the compiler, which reduces resource usage.\n",
    "\n",
    "To get sparse weight matrices regularization can be used to reduce weight magnitude and pruning can be then schedules to incrementaly remove and mask low magnitude weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "784e51db-d8f4-454c-9066-0e0d068c7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "\n",
    "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=100, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1110a7c7-af0b-4a97-82fe-707b0fea3e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.7687 - accuracy: 0.7402 - val_loss: 0.7458 - val_accuracy: 0.7475\n",
      "Epoch 2/5\n",
      "3891/3891 [==============================] - 12s 3ms/step - loss: 0.7353 - accuracy: 0.7494 - val_loss: 0.7324 - val_accuracy: 0.7505\n",
      "Epoch 3/5\n",
      "3891/3891 [==============================] - 11s 3ms/step - loss: 0.7242 - accuracy: 0.7522 - val_loss: 0.7234 - val_accuracy: 0.7526\n",
      "Epoch 4/5\n",
      "3891/3891 [==============================] - 13s 3ms/step - loss: 0.7148 - accuracy: 0.7547 - val_loss: 0.7151 - val_accuracy: 0.7551\n",
      "Epoch 5/5\n",
      "3891/3891 [==============================] - 16s 4ms/step - loss: 0.7089 - accuracy: 0.7563 - val_loss: 0.7101 - val_accuracy: 0.7555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x75d2e8802140>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    X_train_val,\n",
    "    y_train_val,\n",
    "    batch_size=128,\n",
    "    epochs=5,\n",
    "    validation_split=0.25,\n",
    "    shuffle=True,\n",
    "    callbacks=[pruning_callbacks.UpdatePruningStep()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cc36376a-4d7a-4aed-a105-701bf8e57c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip pruning\n",
    "\n",
    "model = strip_pruning(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0dcd31ad-d200-4d73-9f7e-d1b1de2a941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.0% sparsity for layer fc1\n",
      "0.0% sparsity for layer relu1\n",
      "75.0% sparsity for layer fc2\n",
      "0.0% sparsity for layer relu2\n",
      "75.0% sparsity for layer fc3\n",
      "0.0% sparsity for layer relu3\n",
      "75.0% sparsity for layer output\n",
      "0.0% sparsity for layer softmax\n"
     ]
    }
   ],
   "source": [
    "for i, l in zip(model.get_weights(), model.layers):\n",
    "    print(f\"{np.sum(i.flatten()==0)/i.flatten().shape[0]*100:.1f}% sparsity for layer {l.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f345d5cc-55d8-4a26-b93e-730e7680c155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "-----------------------------------\n",
      "Configuration\n",
      "{'Model': {'Precision': {'default': 'fixed<16,6>'}, 'ReuseFactor': 1, 'Strategy': 'Latency', 'BramFactor': 1000000000, 'TraceOutput': False}}\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model', backend='oneAPI')\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "print(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model, hls_config=config, backend='oneAPI', output_dir='model_3/hls4ml_prj', part='Agilex7'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a173d38-2d47-451a-bd81-a363ce15be3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "/opt/intel/oneapi/2025.0/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/lauri/local/icl/notebooks/model_1/hls4ml_prj/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/myproject_bridge.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libmyproject-f833531a.so\u001b[0m\n",
      "[100%] Built target lib\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "y_hls = hls_model.predict(X_test)\n",
    "\n",
    "hls_accuracy = np.sum(np.argmax(y_test, axis=1) == np.argmax(y_hls, axis=1))/y_test.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "584c6195-471f-49ec-bfd3-c9a73ab75bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achieved test accuracy of 75.50%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Achieved test accuracy of {(100 * hls_accuracy):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f9923bc6-9fc0-498a-94c3-75a971a71d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/2025.0/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/lauri/local/icl/notebooks/model_1/hls4ml_prj/build\n",
      "[ 25%] \u001b[34m\u001b[1mTo compile manually:\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -I../src -I../src/firmware -fsycl -fintelfpga -Wall -qactypes -Wno-unused-label -fconstexpr-steps=134217728 -DFPGA_HARDWARE -c ../src/firmware/myproject.cpp -o CMakeFiles/report.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -I../src -I../src/firmware -fsycl -fintelfpga -Wall -qactypes -Wno-unused-label -fconstexpr-steps=134217728 -DFPGA_HARDWARE -c ../src/myproject_test.cpp -o CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "\u001b[34m\u001b[1m\u001b[0m\n",
      "\u001b[34m\u001b[1mTo link manually:\u001b[0m\n",
      "\u001b[34m\u001b[1m/opt/intel/oneapi/2025.0/bin/icpx -fsycl -fintelfpga -Wno-unused-label -fconstexpr-steps=134217728 -Xshardware -Xstarget=Agilex7 -Wno-unused-label -fsycl-link=early -o myproject.report CMakeFiles/report.dir/src/firmware/myproject.cpp.o CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "[ 25%] Built target displayReportCompileCommands\n",
      "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/report.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/report.dir/src/myproject_test.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable myproject.report\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "icpx: warning: appending to an existing archive 'myproject.report' [-Warchive-append]\n",
      "Segmentation fault (core dumped)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Built target report\n",
      "['ALUTs ', 'FFs  ', 'RAMs ', 'DSPs ', 'MLABs', 'Frac. DSPs']\n",
      "['974400', '1948800', '7110', '4510', '24360', '0']\n",
      "[42837, 47838, 8, 5, 19, 5]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hls_model.build(build_type='report')\n",
    "with open(\"model_3/hls4ml_prj/build/myproject.report.prj/reports/resources/json/summary.ndjson\", \"r\") as f:\n",
    "    summary = ndjson.load(f)\n",
    "\n",
    "resource_names = list(filter(lambda x: x[\"name\"] == \"Estimated Resource Usage\", summary))[0]['columns'][1:]\n",
    "available = list(filter(lambda x: x[\"name\"] == \"Available\", summary))[0]['data']\n",
    "estimated_resources = list(filter(lambda x: x[\"name\"] == \"Total\", summary))[0]['data']\n",
    "\n",
    "print(resource_names)\n",
    "print(available)\n",
    "print(estimated_resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91142512-be9a-45e6-95f3-6d0f82f3f89a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Train models with different sparsity. Plot the performance and resource usage as function of model sparsity.\n",
    "\n",
    "How large are the savings in resource usage in comparison to the baseline model before accuracy drops?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f3195-7eff-4594-8b50-5d146bb5b636",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#C2F5DD\">\n",
    "\n",
    "\n",
    "# Exercise\n",
    "\n",
    "Train and synthesize model that uses both quantization aware training and pruning that achieves the same accuracy as the baseline model.\n",
    "\n",
    "How large are the savings in resource usage in comparison to the baseline model before accuracy drops?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
